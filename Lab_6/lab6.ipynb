{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac9155b9f5e04400957a6f8bb3f6610c",
        "deepnote_cell_type": "markdown",
        "id": "2v2D1coL7I8i"
      },
      "source": [
        "<h1><center>Laboratorio 6: La solicitud de Sergio ü§ó</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d3d6f6d405c54dbe985a5f4b3e4f9120",
        "deepnote_cell_type": "markdown",
        "id": "YxdTmIPD7L_x"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Ignacio Meza, Sebasti√°n Tinoco\n",
        "- Auxiliar: Catherine Benavides\n",
        "- Ayudante: Nicol√°s Ojeda, Eduardo Moya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "851a7788e8214942863cbd4099064ab2",
        "deepnote_cell_type": "markdown",
        "id": "Y2Gyrj-x7N2L"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Maximiliano Quintero\n",
        "- Nombre de alumno 2: Tom√°s Apablaza\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f23a189afdec4e198683308db70e43b7",
        "deepnote_cell_type": "markdown",
        "id": "jQ9skYc57Pxi"
      },
      "source": [
        "### **Link de repositorio de GitHub:** `http://....`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5318f41cda64d4290a7a548956ed725",
        "deepnote_cell_type": "markdown",
        "id": "1M4PoEWm7S80"
      },
      "source": [
        "## Temas a tratar\n",
        "- Aplicar Pandas para obtener caracter√≠sticas de un DataFrame.\n",
        "- Aplicar Pipelines y Column Transformers.\n",
        "- Utilizar diferentes algoritmos de cluster y ver el desempe√±o.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Prohibidas las copias.\n",
        "- Pueden usar cualquer matrial del curso que estimen conveniente.\n",
        "- C√≥digo que no se pueda ejecutar, no ser√° revisado.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo aplicar pipelines de Scikit-Learn para generar clusters.\n",
        "- Familiarizarse con plotly.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos (*o tensores*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "858df483d9e64780a21674afed1d34b8",
        "deepnote_cell_type": "markdown",
        "id": "SuMbiyQZG2Cc"
      },
      "source": [
        "## Descripci√≥n del laboratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "403ffe48ec994afda4b91e670a08d0ef",
        "deepnote_cell_type": "markdown",
        "id": "QZsNO4rUrqCz"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/5a/a6/af/5aa6afde8490da403a21601adf7a7240.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0303baa17d4546feae8c9b88c58470bf",
        "deepnote_cell_type": "markdown",
        "id": "2o0MPuk8rqCz"
      },
      "source": [
        "En el coraz√≥n de las operaciones de Aerol√≠nea Lucero, Sergio, el gerente de an√°lisis de datos, reuni√≥ a un talentoso equipo de j√≥venes cient√≠ficos de datos para un desaf√≠o crucial: segmentar la base de datos de los clientes. ‚ÄúNuestro objetivo es descubrir patrones en el comportamiento de los pasajeros que nos permitan personalizar servicios y optimizar nuestras campa√±as de marketing,‚Äù explic√≥ Sergio, mientras desplegaba un amplio rango de datos que inclu√≠an desde h√°bitos de compra hasta opiniones sobre los vuelos.\n",
        "\n",
        "Sergio encarg√≥ a los cient√≠ficos de datos la tarea de aplicar t√©cnicas avanzadas de clustering para identificar distintos segmentos de clientes, como los viajeros frecuentes y aquellos que eligen la aerol√≠nea para celebrar ocasiones especiales. La meta principal era entender profundamente c√≥mo estos grupos perciben la calidad y satisfacci√≥n de los servicios ofrecidos por la aerol√≠nea.\n",
        "\n",
        "A trav√©s de un enfoque meticuloso y colaborativo, los cient√≠ficos de datos se abocaron a la tarea, buscando transformar los datos brutos en valiosos insights que permitir√≠an a Aerol√≠nea Lucero no solo mejorar su servicio, sino tambi√©n fortalecer las relaciones con sus clientes mediante una oferta m√°s personalizada y efectiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e78cb41b144041af98928ab26dcfdaa9",
        "deepnote_cell_type": "markdown",
        "id": "hs4KKWF1Hdpo"
      },
      "source": [
        "## Importamos librerias utiles üò∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "95a5533cfd6d49cfb9afc111c44d224f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 15,
        "execution_start": 1714107106552,
        "id": "a4YpMafirqC0",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "acbeab32db6146678e75448dddf43da8",
        "deepnote_cell_type": "markdown",
        "id": "UQOXod4gHhSq"
      },
      "source": [
        "## 1. Estudio de Performance üìà\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "704b56b978254ad3ae12cdbf58f4832d",
        "deepnote_cell_type": "markdown",
        "id": "Gn5u5ICkrqC2"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://user-images.githubusercontent.com/57133330/188281408-c67df9ee-fd1f-4b37-833b-f02848f1ce02.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d35fbdcc5ef045d6a2822622f0714179",
        "deepnote_cell_type": "markdown",
        "id": "y4Z0jTjtrqC2"
      },
      "source": [
        "Don Sergio les ha encomendado su primera tarea: analizar diversas t√©cnicas de clustering. Su objetivo es entender detalladamente c√≥mo funcionan estos m√©todos en t√©rminos de segmentaci√≥n y eficiencia en tiempo de ejecuci√≥n.\n",
        "\n",
        "Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering (k-means, DBSCAN, Ward y GMM) aplicados a tres conjuntos de datos, incrementando progresivamente su tama√±o. Utilice Plotly para las gr√°ficas y discuta los resultados tanto cualitativa como cuantitativamente.\n",
        "\n",
        "Uno de los requisitos establecidos por Sergio es que el an√°lisis se lleve a cabo utilizando Plotly; de no ser as√≠, se considerar√° incorrecto. Para facilitar este proceso, se ha proporcionado un c√≥digo de Plotly que puede servir como base para realizar las gr√°ficas. Ap√≥yese en el c√≥digo entregado para efectuar el an√°lisis y tome como referencia la siguiente imagen para realizar los gr√°ficos:\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-04-26_at_9.10.44_AM.png' width=300 />\n",
        "\n",
        "En el gr√°fico se visualizan en dos dimensiones los diferentes tipos de datos proporcionados en `datasets`. Cada columna corresponde a un modelo de clustering diferente, mientras que cada fila representa un conjunto de datos distinto. Cada uno de los gr√°ficos incluye el tiempo en segundos que tarda el an√°lisis y la m√©trica Silhouette obtenida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "37580aab6cef4238a8ce42c50a6d35de",
        "deepnote_cell_type": "markdown",
        "id": "maCUNAvZrqC2"
      },
      "source": [
        "Para ser m√°s espec√≠ficos, usted debe cumplir los siguientes objetivos:\n",
        "1. Generar una funci√≥n que permita replicar el gr√°fico expuesto en la imagen (no importa que los colores calcen). [4 puntos]\n",
        "2. Ejecuta la funci√≥n para un `n_samples` igual a 1000, 5000, 20000. [2 puntos]\n",
        "3. Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering. [4 puntos]\n",
        "\n",
        "\n",
        "> ‚ùó Tiene libertad absoluta de escoger los hiper par√°metros de los cluster, sin embargo, se recomienda verificar el dominio de las variables para realizar la segmentaci√≥n.\n",
        "> ‚ùó Recuerde que es obligatorio el uso de plotly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "7f7c25e366754595b13fc2e8116f65a0",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 78,
        "execution_start": 1714107108441,
        "id": "i0IZPGPOrqC3",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "En la siguiente celda se crean los datos ficticios a usar en la secci√≥n 1 del lab.\n",
        "‚ùóNo realice cambios a esta celda\n",
        "\"\"\"\n",
        "\n",
        "# Datos a utilizar\n",
        "\n",
        "# Configuracion\n",
        "n_samples = 5000\n",
        "\n",
        "# Lunas\n",
        "moons = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=30)\n",
        "\n",
        "# Blobs\n",
        "blobs = datasets.make_blobs(n_samples=n_samples, random_state=172)\n",
        "\n",
        "# Datos desiguales\n",
        "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
        "mutated = (np.dot(blobs[0], transformation), blobs[1])\n",
        "\n",
        "# Generamos Dataset\n",
        "datasets = {\n",
        "    'moons':{\n",
        "        'x': moons[0], 'classes': moons[1], 'n_cluster': 2\n",
        "    },\n",
        "    'blobs':{\n",
        "        'x': blobs[0], 'classes': blobs[1], 'n_cluster': 3\n",
        "    },\n",
        "    'mutated':{\n",
        "        'x': mutated[0], 'classes': mutated[1], 'n_cluster': 3\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "643d6b35af5541358f481fda4d3fc51f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 267,
        "execution_start": 1714108733824,
        "id": "CO3JFqezrqC3",
        "outputId": "61a8cca1-3460-44dc-c23f-7dffb853b9a6",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "# Funci√≥n scatter\n",
        "def plot_scatter(x, y, color):\n",
        "    fig = go.Figure(data=[go.Scatter(\n",
        "        x=x, y=y, mode='markers',\n",
        "        marker=dict(\n",
        "            size=8,\n",
        "            color=color,  # corresponde a una variable por el cual colorear\n",
        "            showscale=False  # esconde la escala de color\n",
        "        )\n",
        "    )])\n",
        "    return fig\n",
        "\n",
        "# Multiples plots con plotly\n",
        "fig = make_subplots(rows=3, cols=1)\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['moons']['x'][:, 0],\n",
        "        y=datasets['moons']['x'][:, 1],\n",
        "        color=datasets['moons']['classes']\n",
        "    )._data[0],\n",
        "    row=1, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['blobs']['x'][:, 0],\n",
        "        y=datasets['blobs']['x'][:, 1],\n",
        "        color=datasets['blobs']['classes']\n",
        "    )._data[0],\n",
        "    row=2, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['mutated']['x'][:, 0],\n",
        "        y=datasets['mutated']['x'][:, 1],\n",
        "        color=datasets['mutated']['classes']\n",
        "    )._data[0],\n",
        "    row=3, col=1\n",
        ")\n",
        "fig.update_layout(\n",
        "    showlegend=False, template='simple_white'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y51s6f_UtIkc"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gja27MJstPbv"
      },
      "outputs": [],
      "source": [
        "# Escriba su c√≥digo aqu√≠\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.cluster import AgglomerativeClustering \n",
        "from sklearn.metrics import silhouette_score\n",
        "import time\n",
        "\n",
        "X_moons = datasets[\"moons\"][\"x\"]\n",
        "X_blobs = datasets[\"blobs\"][\"x\"]\n",
        "X_mutated = datasets[\"mutated\"][\"x\"]\n",
        "\n",
        "######################## K_means\n",
        "\n",
        "# Instancia de KMeans\n",
        "\n",
        "\n",
        "kmeans_moons = KMeans(n_clusters=2)\n",
        "kmeans_blobs = KMeans(n_clusters=3)\n",
        "kmeans_mutated = KMeans(n_clusters=3)\n",
        "\n",
        "\n",
        "kmeans_start_time = time.perf_counter_ns()\n",
        "kmeans_moons.fit(X_moons)\n",
        "kmeans_moons_time = time.perf_counter_ns()\n",
        "kmeans_blobs.fit(X_blobs)\n",
        "kmeans_blobs_time = time.perf_counter_ns()\n",
        "kmeans_mutated.fit(X_mutated)\n",
        "kmeans_mutated_time = time.perf_counter_ns()\n",
        "\n",
        "kmeans_elapsed_time_1 = kmeans_moons_time - kmeans_start_time\n",
        "kmeans_elapsed_time_2 = kmeans_blobs_time - kmeans_moons_time \n",
        "kmeans_elapsed_time_3 = kmeans_mutated_time - kmeans_blobs_time\n",
        "\n",
        "kmeans_silhouette_score_moons = silhouette_score(X_moons, kmeans_moons.labels_)\n",
        "kmeans_silhouette_score_blobs = silhouette_score(X_blobs, kmeans_blobs.labels_)\n",
        "kmeans_silhouette_score_mutated = silhouette_score(X_mutated, kmeans_mutated.labels_)\n",
        "\n",
        "########################### DBSCAN\n",
        "\n",
        "# Par√°metros para DBSCAN\n",
        "eps = 0.2 # Radio de la vecindad\n",
        "min_samples = 5 # N√∫mero m√≠nimo de muestras en una vecindad para formar un cl√∫ster\n",
        "\n",
        "# Aplicar DBSCAN a cada conjunto de datos generado\n",
        "\n",
        "dbscan_moons = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "dbscan_blobs = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "dbscan_mutated = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "\n",
        "\n",
        "dbs_start_time = time.perf_counter_ns()\n",
        "dbs_moons_labels= dbscan_moons.fit_predict(X_moons)\n",
        "dbs_moons_time = time.perf_counter_ns()\n",
        "dbs_blobs_labels = dbscan_blobs.fit_predict(X_blobs)\n",
        "dbs_blobs_time = time.perf_counter_ns()\n",
        "dbs_mutated_labels= dbscan_mutated.fit_predict(X_mutated)\n",
        "dbs_mutated_time = time.perf_counter_ns()\n",
        "\n",
        "dbs_elapsed_time_1 = dbs_moons_time - dbs_start_time\n",
        "dbs_elapsed_time_2 = dbs_blobs_time - dbs_moons_time \n",
        "dbs_elapsed_time_3 = dbs_mutated_time - dbs_blobs_time\n",
        "\n",
        "dbs_silhouette_score_moons = silhouette_score(X_moons, dbs_moons_labels)\n",
        "dbs_silhouette_score_blobs = silhouette_score(X_blobs, dbs_blobs_labels)\n",
        "dbs_silhouette_score_mutated = silhouette_score(X_mutated, dbs_mutated_labels)\n",
        "\n",
        "\n",
        "\n",
        "####################### GMM\n",
        "\n",
        "# Par√°metros para GMM\n",
        "n_components = 3  # N√∫mero de componentes Gaussianos\n",
        "\n",
        "# Aplicar GMM a cada conjunto de datos generado\n",
        "\n",
        "gmm_moons = GaussianMixture(n_components=2)\n",
        "gmm_blobs = GaussianMixture(n_components=n_components)\n",
        "gmm_mutated = GaussianMixture(n_components=n_components)\n",
        "\n",
        "\n",
        "\n",
        "gmm_start_time = time.perf_counter_ns()\n",
        "gmm_labels_moons = gmm_moons.fit_predict(X_moons)\n",
        "gmm_moons_time = time.perf_counter_ns()\n",
        "gmm_labels_blobs = gmm_blobs.fit_predict(X_blobs)\n",
        "gmm_blobs_time = time.perf_counter_ns()\n",
        "gmm_labels_mutated = gmm_mutated.fit_predict(X_mutated)\n",
        "gmm_mutated_time = time.perf_counter_ns()\n",
        "\n",
        "\n",
        "\n",
        "gmm_elapsed_time_1 = gmm_moons_time - gmm_start_time\n",
        "gmm_elapsed_time_2 = gmm_blobs_time - gmm_moons_time \n",
        "gmm_elapsed_time_3 = gmm_mutated_time - gmm_blobs_time\n",
        "\n",
        "gmm_silhouette_score_moons = silhouette_score(X_moons, gmm_labels_moons)\n",
        "gmm_silhouette_score_blobs = silhouette_score(X_blobs, gmm_labels_blobs)\n",
        "gmm_silhouette_score_mutated = silhouette_score(X_mutated, gmm_labels_mutated)\n",
        "\n",
        "################################ WARD\n",
        "\n",
        "# Par√°metros para AgglomerativeClustering\n",
        "n_clusters = 3  # N√∫mero de cl√∫steres\n",
        "\n",
        "# Aplicar AgglomerativeClustering a cada conjunto de datos generado\n",
        "\n",
        "ward_moons = AgglomerativeClustering(n_clusters=2, linkage='ward')\n",
        "ward_blobs = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
        "ward_mutated = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
        "\n",
        "\n",
        "\n",
        "ward_start_time = time.perf_counter_ns()\n",
        "ward_labels_moons = ward_moons.fit_predict(X_moons)\n",
        "ward_moons_time = time.perf_counter_ns()\n",
        "ward_labels_blobs = ward_blobs.fit_predict(X_blobs)\n",
        "ward_blobs_time = time.perf_counter_ns()\n",
        "ward_labels_mutated = ward_mutated.fit_predict(X_mutated)\n",
        "ward_mutated_time = time.perf_counter_ns()\n",
        "\n",
        "\n",
        "\n",
        "ward_elapsed_time_1 = ward_moons_time - ward_start_time\n",
        "ward_elapsed_time_2 = ward_blobs_time - ward_moons_time \n",
        "ward_elapsed_time_3 = ward_mutated_time - ward_blobs_time\n",
        "\n",
        "ward_silhouette_score_moons = silhouette_score(X_moons, ward_labels_moons)\n",
        "ward_silhouette_score_blobs = silhouette_score(X_blobs, ward_labels_blobs)\n",
        "ward_silhouette_score_mutated = silhouette_score(X_mutated, ward_labels_mutated)\n",
        "# Graficamos\n",
        "\n",
        "# Multiples plots con plotly\n",
        "fig = make_subplots(rows=3, cols=4, subplot_titles=(f\"K_means: {kmeans_elapsed_time_1/1e9:.4f}[s], silueta: {kmeans_silhouette_score_moons:.2f}\",\n",
        "                                                    f\"DBSCAN: {dbs_elapsed_time_1/1e9:.4f}[s], silueta: {dbs_silhouette_score_moons:.2f}\",\n",
        "                                                    f\"GMM: {gmm_elapsed_time_1/1e9:.4f}[s], silueta: {gmm_silhouette_score_moons:.2f}\",\n",
        "                                                    f\"Ward: {ward_elapsed_time_1/1e9:.4f}[s], silueta: {ward_silhouette_score_moons:.2f}\",\n",
        "                                                    f\"K_means: {kmeans_elapsed_time_2/1e9:.4f}[s], silueta: {kmeans_silhouette_score_blobs:.2f}\",\n",
        "                                                    f\"DBSCAN: {dbs_elapsed_time_2/1e9:.4f}[s], silueta: {dbs_silhouette_score_blobs:.2f}\",\n",
        "                                                    f\"GMM: {gmm_elapsed_time_2/1e9:.4f}[s], silueta: {gmm_silhouette_score_blobs:.2f}\",\n",
        "                                                    f\"Ward: {ward_elapsed_time_2/1e9:.4f}[s], silueta: {ward_silhouette_score_blobs:.2f}\",\n",
        "                                                    f\"K_means: {kmeans_elapsed_time_3/1e9:.4f}[s], silueta: {kmeans_silhouette_score_mutated:.2f}\",\n",
        "                                                    f\"DBSCAN: {dbs_elapsed_time_3/1e9:.4f}[s], silueta: {dbs_silhouette_score_mutated:.2f}\",\n",
        "                                                    f\"GMM: {gmm_elapsed_time_3/1e9:.4f}[s], silueta: {gmm_silhouette_score_mutated:.2f}\",\n",
        "                                                    f\"Ward: {ward_elapsed_time_3/1e9:.4f}[s], silueta: {ward_silhouette_score_mutated:.2f}\"))\n",
        "########### KMEANS\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['moons']['x'][:, 0],\n",
        "        y=datasets['moons']['x'][:, 1],\n",
        "        color= kmeans_moons.labels_\n",
        "    )._data[0],\n",
        "    row=1, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['blobs']['x'][:, 0],\n",
        "        y=datasets['blobs']['x'][:, 1],\n",
        "        color=kmeans_blobs.labels_\n",
        "    )._data[0],\n",
        "    row=2, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['mutated']['x'][:, 0],\n",
        "        y=datasets['mutated']['x'][:, 1],\n",
        "        color=kmeans_mutated.labels_\n",
        "    )._data[0],\n",
        "    row=3, col=1\n",
        ")\n",
        "################### DBS \n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['moons']['x'][:, 0],\n",
        "        y=datasets['moons']['x'][:, 1],\n",
        "        color= dbs_moons_labels\n",
        "    )._data[0],\n",
        "    row=1, col=2\n",
        ")\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['blobs']['x'][:, 0],\n",
        "        y=datasets['blobs']['x'][:, 1],\n",
        "        color= dbs_blobs_labels\n",
        "    )._data[0],\n",
        "    row=2, col=2\n",
        ")\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['mutated']['x'][:, 0],\n",
        "        y=datasets['mutated']['x'][:, 1],\n",
        "        color=dbs_mutated_labels\n",
        "    )._data[0],\n",
        "    row=3, col= 2 \n",
        ")\n",
        "############################# GMM\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['moons']['x'][:, 0],\n",
        "        y=datasets['moons']['x'][:, 1],\n",
        "        color= gmm_labels_moons\n",
        "    )._data[0],\n",
        "    row=1, col=3\n",
        ")\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['blobs']['x'][:, 0],\n",
        "        y=datasets['blobs']['x'][:, 1],\n",
        "        color= gmm_labels_blobs\n",
        "    )._data[0],\n",
        "    row=2, col=3\n",
        ")\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['mutated']['x'][:, 0],\n",
        "        y=datasets['mutated']['x'][:, 1],\n",
        "        color= gmm_labels_mutated\n",
        "    )._data[0],\n",
        "    row=3, col= 3 \n",
        ")\n",
        "####################### WARD \n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['moons']['x'][:, 0],\n",
        "        y=datasets['moons']['x'][:, 1],\n",
        "        color= ward_labels_moons\n",
        "    )._data[0],\n",
        "    row=1, col=4\n",
        ")\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['blobs']['x'][:, 0],\n",
        "        y=datasets['blobs']['x'][:, 1],\n",
        "        color= ward_labels_blobs\n",
        "    )._data[0],\n",
        "    row=2, col=4\n",
        ")\n",
        "fig.add_trace(\n",
        "    plot_scatter(\n",
        "        x=datasets['mutated']['x'][:, 0],\n",
        "        y=datasets['mutated']['x'][:, 1],\n",
        "        color= ward_labels_mutated\n",
        "    )._data[0],\n",
        "    row=3, col=4  \n",
        ")\n",
        "fig.update_layout(title_text = \"Comparaci√≥n de tiempos de ejecuci√≥n por t√©cnica\")\n",
        "fig.update_layout(\n",
        "    showlegend=False, template='simple_white'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "13c5cb8067d9415f83b3d497954a437a",
        "deepnote_cell_type": "markdown",
        "id": "3mCbZc86rqC6"
      },
      "source": [
        "## 2. An√°lisis de Satisfacci√≥n de Vuelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd6e991646b44f50a4b13f01d1542415",
        "deepnote_cell_type": "markdown",
        "id": "JI33m5jbrqC6"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/2Hci.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5742dfbd5a2e43778ff250436bab1005",
        "deepnote_cell_type": "markdown",
        "id": "h5k24znirqC7"
      },
      "source": [
        "Habiendo entendido c√≥mo funcionan los modelos de aprendizaje no supervisado, *Don Sergio* le encomienda estudiar la satisfacci√≥n de pasajeros al haber tomado un vuelo en alguna de sus aerolineas. Para esto, el magnate le dispone del dataset `aerolineas_licer.parquet`, el cual contiene el grado de satisfacci√≥n de los clientes frente a diferentes aspectos del vuelo. Las caracter√≠sticas del vuelo se definen a continuaci√≥n:\n",
        "\n",
        "- *Gender*: G√©nero de los pasajeros (Femenino, Masculino)\n",
        "- *Customer Type*: Tipo de cliente (Cliente habitual, cliente no habitual)\n",
        "- *Age*: Edad actual de los pasajeros\n",
        "- *Type of Travel*: Prop√≥sito del vuelo de los pasajeros (Viaje personal, Viaje de negocios)\n",
        "- *Class*: Clase de viaje en el avi√≥n de los pasajeros (Business, Eco, Eco Plus)\n",
        "- *Flight distance*: Distancia del vuelo de este viaje\n",
        "- *Inflight wifi service*: Nivel de satisfacci√≥n del servicio de wifi durante el vuelo (0:No Aplicable; 1-5)\n",
        "- *Departure/Arrival time convenient*: Nivel de satisfacci√≥n con la conveniencia del horario de salida/llegada\n",
        "- *Ease of Online booking*: Nivel de satisfacci√≥n con la facilidad de reserva en l√≠nea\n",
        "- *Gate location*: Nivel de satisfacci√≥n con la ubicaci√≥n de la puerta\n",
        "- *Food and drink*: Nivel de satisfacci√≥n con la comida y la bebida\n",
        "- *Online boarding*: Nivel de satisfacci√≥n con el embarque en l√≠nea\n",
        "- *Seat comfort*: Nivel de satisfacci√≥n con la comodidad del asiento\n",
        "- *Inflight entertainment*: Nivel de satisfacci√≥n con el entretenimiento durante el vuelo\n",
        "- *On-board service*: Nivel de satisfacci√≥n con el servicio a bordo\n",
        "- *Leg room service*: Nivel de satisfacci√≥n con el espacio para las piernas\n",
        "- *Baggage handling*: Nivel de satisfacci√≥n con el manejo del equipaje\n",
        "- *Check-in service*: Nivel de satisfacci√≥n con el servicio de check-in\n",
        "- *Inflight service*: Nivel de satisfacci√≥n con el servicio durante el vuelo\n",
        "- *Cleanliness*: Nivel de satisfacci√≥n con la limpieza\n",
        "- *Departure Delay in Minutes*: Minutos de retraso en la salida\n",
        "- *Arrival Delay in Minutes*: Minutos de retraso en la llegada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOoIFHpw5xCW"
      },
      "source": [
        "En consideraci√≥n de lo anterior, realice las siguientes tareas:\n",
        "\n",
        "0. Ingeste el dataset a su ambiente de trabajo.\n",
        "\n",
        "1. Seleccione **s√≥lo las variables num√©ricas del dataset**.  Explique qu√© √©fectos podr√≠a usar variables categ√≥ricas en un algoritmo no supervisado. Los datos se encuentran en el siguiente [enlace](https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/aerolineas_lucer.parquet). [2 puntos]\n",
        "\n",
        "2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 puntos]\n",
        "\n",
        "3. Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n. [2 puntos]\n",
        "\n",
        "4. Examine la correlaci√≥n entre las variables mediante un correlograma. [2 puntos]\n",
        "\n",
        "5. De acuerdo con los resultados obtenidos en 5, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO6tcVBCtxxS"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzHTZ17xveU_"
      },
      "outputs": [],
      "source": [
        "# Carga de datos\n",
        "df =pd.read_parquet(\"C:/Users/Tomas/OneDrive/Documentos/Universidad/Semestre 13/Laboratorio de Programaci√≥n Cient√≠fica/lab 6/aerolineas_lucer.parquet\")\n",
        "numeric_cols = df.select_dtypes(int or float).columns \n",
        "df_numerica = df[numeric_cols]\n",
        "\n",
        "\n",
        "# Iterar sobre cada columna num√©rica y crear un histograma\n",
        "for col in df_numerica.columns:\n",
        "    fig = go.Figure(data=[go.Histogram(x=df_numerica[col])])\n",
        "    fig.update_layout(\n",
        "        title=f'Histograma de {col}',\n",
        "        xaxis_title='Valor',\n",
        "        yaxis_title='Frecuencia',\n",
        "        bargap=0.1, # Espacio entre barras\n",
        "        bargroupgap=0.1 # Espacio entre grupos de barras\n",
        "    )\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2)\n",
        "El efecto que podr√≠a tener la creaci√≥n de variables categoricas en los algoritmos, es que primer lugar es necesario codificarlas en variables binarias para su interprestaci√≥n por la maquina y por otro lado que no todas las algoritmos no supervisados soportan este tipo de variables, pues trabajan con distancias como la euclidiana.\n",
        "# 3)\n",
        "Se observa que las variables Departure Delay in Minutes y Flight Distance, tienen muchos valores fuera de rango o outliers, que pueden generar ruido en la ejecuci√≥n de los algortimos. Por otro lado, la escala de la mayoria de las variables tienen diferentes ordenes de magnitud en comparaci√≥n a algunas, lo que tambien puede generar distorciones en la captura de patrones de los algoritmos. Por lo que conviene escalar aquellas variables que se mueven en rangos muy diferentes como Departure Delay in Minutes y Flight Distance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Calcular la matriz de correlaci√≥n\n",
        "correlation_matrix = df_numerica.corr()\n",
        "\n",
        "# Crear un gr√°fico de correlaci√≥n con Plotly\n",
        "fig = px.imshow(correlation_matrix,\n",
        "                labels=dict(x=\"Variables\", y=\"Variables\", color=\"Correlaci√≥n\"),\n",
        "                x=correlation_matrix.index,\n",
        "                y=correlation_matrix.columns,\n",
        "                color_continuous_scale='RdBu_r')\n",
        "\n",
        "fig.update_layout(title='Gr√°fico de Correlaci√≥n', width=800, height=800) \n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5) \n",
        " La elecci√≥n del conjunto de 4 variables se determinar√°, considerando la m√≠nima correlaci√≥n entre ellas mismas, pero que se correlacionen lo m√°s posible con las otras, dado que se espera que las variables otorguen informaci√≥n nueva que no aporten las otras variables y que generalice a grandes rasgos la informaci√≥n de las dem√°s variables. Ponderando adem√°s que su elecci√≥n tenga justificaci√≥n con el motivo del problema ,es decir, agrupar la satisfacci√≥n del cliente. En primer lugar se elige Inflight entertaiment, pues, es la que m√°s se correlaciona con las dem√°s y puede agurpar bien el comportamiento de los clientes, segun su satisfacci√≥n. En segundo lugar se elige Ease of Online booking, pues, no parece correlacionarse con la primera elecci√≥n y se correlaciona con muchas otras variables, adem√°s, permitiria obtener informaci√≥n del servicio online. On-boar Service, permitir√° ponderar a grandes rasgos la satisfacci√≥n de cliente en vuelo. Y finalmente, Age, pues nos se correlaciona con ninguna de las anteriores y esta en ordenes de magnitud aceptables y por otro lado otorga informaci√≥n del propio cliente para la confromaci√≥n de los clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_conjunto = df_numerica[[\"Ease of Online booking\",\"Inflight entertainment\",\"On-board service\",\"Age\"]]\n",
        "df_conjunto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "4b6c047d994f40ea9e78a36a777042e0",
        "deepnote_cell_type": "markdown",
        "id": "PNGfTgtkrqC9"
      },
      "source": [
        "## 3. Preprocesamiento üé≠"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "713b3f0e61dd4841bb5b38c730d344d5",
        "deepnote_cell_type": "markdown",
        "id": "6RZD0fMNrqC-"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/1e/a8/0e/1ea80e7cea0d429146580c7e91c5b944.gif\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "98400c7b5fec4af193eec3601f53891e",
        "deepnote_cell_type": "markdown",
        "id": "J6d4VEOTrqC-"
      },
      "source": [
        "Tras quedar satisfecho con los resultados presentados en el punto 2, el due√±o de la empresa ha solicitado que se preprocesen los datos mediante un `pipeline`. Es crucial que este proceso tenga en cuenta las observaciones derivadas de los an√°lisis anteriores. Adicionalmente, ha expresado su inter√©s en visualizar el conjunto de datos en un gr√°fico de dos o tres dimensiones.\n",
        "\n",
        "Bas√°ndose en los an√°lisis realizados anteriormente:\n",
        "1. Cree un `pipeline` que incluya PCA, utilizando las consideraciones mencionadas previamente para proyectar los datos a dos dimensiones. [4 puntos]\n",
        "2. Grafique los resultados obtenidos y comente lo visualizado. [6 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDSaGoq0OUp"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "ad1e70818ad748638ca0927b07a76125",
        "deepnote_cell_type": "code",
        "id": "gBYG238wrqC-"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "np.random.seed(32)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Normaliza los datos\n",
        "    ('pca', PCA(n_components=2))  # Realiza PCA para conservar 2 componentes principales\n",
        "])\n",
        "\n",
        "X_projected = pipeline.fit_transform(df_conjunto)\n",
        "\n",
        "fig = px.scatter(df_conjunto, x=X_projected[:, 0], y=X_projected[:, 1], opacity=0.5,\n",
        "                 title='Proyecci√≥n de datos en 2 dimensiones usando PCA')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El comportamiento de la satisfacci√≥n del cliente parece bastante regular, cas√≠ m√°s una linea de tendencia que la conformaci√≥n de clusters. Parecen existir ciertos outliers, pero no son demasiados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bd281470d3054764a63d857cfa7d52a6",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "7ENoOtIIrqC_"
      },
      "source": [
        "## 4. Outliers üö´üôÖ‚Äç‚ôÄÔ∏è‚ùåüôÖ‚Äç‚ôÇÔ∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "db89e9c9f35c44abbd8991180226c0ea",
        "deepnote_cell_type": "markdown",
        "id": "fbGw6Sa-rqC_"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://joachim-gassen.github.io/images/ani_sim_bad_leverage.gif\" width=250>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3e2f59fa12954641af7a854a4e203694",
        "deepnote_cell_type": "markdown",
        "id": "nl_ccu9brqDA"
      },
      "source": [
        "Con el objetivo de mantener la claridad en su an√°lisis, Don Sergio le ha solicitado entrenar un modelo que identifique pasajeros con comportamientos altamente at√≠picos.\n",
        "\n",
        "1. Utilice `IsolationForest` para clasificar las anomal√≠as del dataset, configurando el modelo para que s√≥lo el 1% de los datos sean considerados an√≥malos. Aseg√∫rese de integrar esta tarea dentro de un `pipeline`. [3 puntos]\n",
        "\n",
        "2. Visualice los resultados en el gr√°fico de dos dimensiones previamente creado. [3 puntos]\n",
        "\n",
        "3. ¬øC√≥mo evaluar√≠a el rendimiento de su modelo en la detecci√≥n de anomal√≠as? [4 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cS1FR00NlF"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "be86896911244aa89e3b5f3f00a286af",
        "deepnote_cell_type": "code",
        "id": "iaPZFmjyrqDA"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "# Crear y ajustar el pipeline con PCA y Isolation Forest\n",
        "outliers_fraction = 0.01\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components=2)),\n",
        "    ('isolation_forest', IsolationForest(contamination=outliers_fraction, random_state=32))\n",
        "])\n",
        "pipeline.fit(df_conjunto)\n",
        "\n",
        "# Proyectar los datos en dos dimensiones\n",
        "X_projected = pipeline[:-1].transform(df_conjunto)\n",
        "\n",
        "df_projected = pd.DataFrame(X_projected, columns=[\"PCA1\", \"PCA2\"])\n",
        "\n",
        "# Agregar una columna al DataFrame original con la etiqueta de anomal√≠a\n",
        "df_projected['anomaly'] = pipeline.predict(df_conjunto)\n",
        "\n",
        "# Visualizar los resultados en Plotly\n",
        "fig = px.scatter(df_projected, x=\"PCA1\", y=\"PCA2\", opacity=0.5,\n",
        "                 color='anomaly', title='Detecci√≥n de anomal√≠as usando Isolation Forest')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pareciera que el modelo de detecci√≥n de anomal√≠as tuvo un buen desempe√±o evaluando de manera gr√°fica en 2 dimensiones, en donde, se puede observar que destaco los puntos que parecen ser externos a los grupos principales, y adem√°s, a√±adi√≥ a los extremos de cada grupo, me imagino que esto se debe a que le asignamos un m√≠nimo de instancias a considerar como anomal√≠as.\n",
        "\n",
        "Para complementar este an√°lisis podr√≠a ser buena idea ocupar m√©tricas de desempe√±o del modelo, como pueden ser el coeficiente silhouette."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3871e2fe5bdd422dbdbfaebf75503ae3",
        "deepnote_cell_type": "markdown",
        "id": "zQFTklmVrqDB"
      },
      "source": [
        "## 5. M√©tricas de Desempe√±o üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "236333de6dd445c182aefcc507589325",
        "deepnote_cell_type": "markdown",
        "id": "YpNj4wbPrqDB"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://giffiles.alphacoders.com/219/219081.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a7e1ceb91be94b1da2ab8be97dfac999",
        "deepnote_cell_type": "markdown",
        "id": "CR3hzRxrrqDB"
      },
      "source": [
        "Motivado por incrementar su fortuna, Don Sergio le solicita entrenar un modelo que le permita segmentar a los pasajeros en grupos distintos, con el objetivo de optimizar las diversas campa√±as de marketing dise√±adas por su equipo. Para ello, le se pide realizar las siguientes tareas:\n",
        "\n",
        "1. Utilizar el modelo **Gaussian Mixture** y explore diferentes configuraciones de n√∫mero de cl√∫sters, espec√≠ficamente entre 3 y 8. Aseg√∫rese de integrar esta operaci√≥n dentro de un `pipeline`. [4 puntos]\n",
        "2. Explique cu√°l ser√≠a el criterio adecuado para seleccionar el n√∫mero √≥ptimo de cl√∫sters. **Justifique de forma estadistica y a traves de gr√°ficos.** [6 puntos]\n",
        "\n",
        "> **HINT:** Se recomienda investigar sobre los criterios AIC y BIC para esta tarea."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_T_zTg0MXB"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "6d3d1bb3fda14321984466d9101a775a",
        "deepnote_cell_type": "code",
        "id": "5GeUb9J3rqDB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import plotly.express as px\n",
        "\n",
        "# Crear un pipeline base con PCA y GMM\n",
        "pipeline_base = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Escalador de caracter√≠sticas\n",
        "    ('pca', PCA(n_components=2)),  # Reducci√≥n de dimensionalidad a 2 componentes\n",
        "])\n",
        "\n",
        "# Rango de n√∫mero de cl√∫sters\n",
        "n_components_range = range(3, 9)\n",
        "\n",
        "# Listas para almacenar los modelos, AIC y BIC\n",
        "models = []\n",
        "# Listas para almacenar los valores de AIC y BIC\n",
        "aic_values = []\n",
        "bic_values = []\n",
        "\n",
        "# Iterar sobre diferentes valores de n_components\n",
        "for n_components in n_components_range:\n",
        "    # Crear un nuevo pipeline con el n√∫mero de componentes espec√≠fico para GMM\n",
        "    pipeline = Pipeline([\n",
        "        ('pipeline_base', pipeline_base),  # Usar el pipeline base\n",
        "        ('gmm', GaussianMixture(n_components=n_components, random_state=32)),  # Modelo de mezcla gaussiana\n",
        "    ])\n",
        "    \n",
        "    # Ajustar el pipeline\n",
        "    pipeline.fit(df_conjunto)\n",
        "\n",
        "    # Proyectar los datos en dos dimensiones\n",
        "    X_projected = pipeline[:-1].transform(df_conjunto)\n",
        "\n",
        "    df_projected = pd.DataFrame(X_projected, columns=[\"PCA1\", \"PCA2\"])\n",
        "    \n",
        "    # Calcular AIC y BIC\n",
        "    aic = pipeline.named_steps['gmm'].aic(X_projected)\n",
        "    bic = pipeline.named_steps['gmm'].bic(X_projected)\n",
        "    \n",
        "    # Almacenar los valores de AIC y BIC\n",
        "    aic_values.append(aic)\n",
        "    bic_values.append(bic)\n",
        "    \n",
        "    # Obtener las etiquetas de cluster para cada muestra\n",
        "    df_projected[\"cluster\"] = pipeline.predict(df_conjunto)\n",
        "    \n",
        "    # Visualizar los clusters\n",
        "    fig = px.scatter(df_projected, x=\"PCA1\", y=\"PCA2\", color='cluster',\n",
        "                     title=f'Clusters resultantes para n_components={n_components}')\n",
        "    fig.show()\n",
        "\n",
        "# Graficar los valores de AIC y BIC en funci√≥n del n√∫mero de cl√∫sters\n",
        "fig = px.line(x=list(n_components_range), y=aic_values, labels={'x': 'N√∫mero de Cl√∫sters', 'y': 'AIC'},\n",
        "              title='Valores de AIC para diferentes n√∫meros de cl√∫sters')\n",
        "fig.add_scatter(x=list(n_components_range), y=bic_values, mode='lines', name='BIC')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analizando visualmente los clusters, podemos notar que no existe un diferenciaci√≥n clara en ninguno, esto se puede deber a su reducci√≥n a dos dimensiones o a el algoritmo utilizado.\n",
        "\n",
        "Observando el √∫ltimo gr√°fico de la m√©trica BIC y utilizando el m√©todo del codo, podemos notar que hay un punto en part√≠cular en donde esta m√©trica disminuye considerablemente y es en 7 clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "dd342e336254418ba766b29dce16b267",
        "deepnote_cell_type": "markdown",
        "id": "P9CERnaerqDC"
      },
      "source": [
        "## 6. An√°lisis de resultados üìä"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "953b5ad01a704b50b899db7176d1b7b2",
        "deepnote_cell_type": "markdown",
        "id": "I1yNa111rqDC"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/7wTk.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd90e2f135404353ac0b5ab844936ca7",
        "deepnote_cell_type": "markdown",
        "id": "dg0Qx4RZrqDC"
      },
      "source": [
        "Una vez identificado el n√∫mero √≥ptimo de cl√∫sters, se le pide realizar lo siguiente:\n",
        "\n",
        "1. Utilizar la proyecci√≥n en dos dimensiones para visualizar cada cl√∫ster claramente. [2 puntos]\n",
        "\n",
        "2. ¬øEs posible distinguir claramente entre los cl√∫sters generados? [2 puntos]\n",
        "\n",
        "3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]\n",
        "\n",
        "4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]\n",
        "\n",
        "5. ¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRN0zZip0IMB"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "9abf4dbc643e40cebe99fcb1ff3ff413",
        "deepnote_cell_type": "code",
        "id": "XmZrz15GrqDC"
      },
      "outputs": [],
      "source": [
        "# Ajustar el pipeline con 4 cl√∫sters\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Escalador de caracter√≠sticas\n",
        "    ('pca', PCA(n_components=2)),  # Reducci√≥n de dimensionalidad a 2 componentes\n",
        "    ('gmm', GaussianMixture(n_components=7, random_state=42)),  # Modelo de mezcla gaussiana con 5 cl√∫sters\n",
        "])\n",
        "pipeline.fit(df_conjunto)\n",
        "\n",
        "X_projected = pipeline[:-1].transform(df_conjunto)\n",
        "df_projected = pd.DataFrame(X_projected, columns=[\"PCA1\", \"PCA2\"])\n",
        "\n",
        "# Agregar las etiquetas de cl√∫ster al DataFrame\n",
        "df_projected['cluster'] = pipeline.predict(df_conjunto)\n",
        "\n",
        "# Visualizar los cl√∫sters en dos dimensiones\n",
        "fig = px.scatter(df_projected, x=\"PCA1\", y=\"PCA2\", color='cluster',\n",
        "                 title='Cl√∫sters en dos dimensiones')\n",
        "fig.show()\n",
        "\n",
        "# Agregar las etiquetas de cl√∫ster al DataFrame\n",
        "df_conjunto['cluster'] = pipeline.predict(df_conjunto)\n",
        "\n",
        "# Calcular las estad√≠sticas descriptivas para cada cl√∫ster\n",
        "cluster_stats = df_conjunto.groupby('cluster').agg(['mean', 'std'])\n",
        "\n",
        "# Mostrar las estad√≠sticas descriptivas\n",
        "print(cluster_stats)\n",
        "\n",
        "# Ajustar el pipeline con 5 cl√∫sters y 3 dimensiones\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Escalador de caracter√≠sticas\n",
        "    ('pca', PCA(n_components=3)),  # Reducci√≥n de dimensionalidad a 3 componentes\n",
        "    ('gmm', GaussianMixture(n_components=7, random_state=42)),  # Modelo de mezcla gaussiana con 5 cl√∫sters\n",
        "])\n",
        "pipeline.fit(df_conjunto)\n",
        "\n",
        "# Proyectar los datos en tres dimensiones\n",
        "X_projected_3d = pipeline[:-1].transform(df_conjunto)\n",
        "\n",
        "df_projected = pd.DataFrame(X_projected_3d, columns=[\"PCA1\", \"PCA2\",\"PCA3\"])\n",
        "\n",
        "df_projected['cluster'] = pipeline.predict(df_conjunto)\n",
        "\n",
        "# Visualizar los cl√∫sters en tres dimensiones\n",
        "fig = px.scatter_3d(df_projected, x=\"PCA1\", y=\"PCA2\", z=\"PCA3\", color='cluster',\n",
        "                     title='Cl√∫sters en tres dimensiones')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En 2 dimensiones es posible observar claramente la divisi√≥n entre clusters, pero pareciera no ser la divisi√≥n √≥ptimo. Esto cambia al verlo en 3 dimensiones, en este caso se puede apreciar mejor la diferenciaci√≥n entre clusters."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "7cb425aec99b4079954fd707109c42c3",
    "deepnote_persisted_session": {
      "createdAt": "2024-04-26T06:15:51.197Z"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
